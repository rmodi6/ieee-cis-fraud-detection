{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datatable as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transaction = dt.fread(\"/home/rmodi/Documents/CSE519/hw2/dataset/test_transaction.csv\").to_pandas()\n",
    "test_identity = dt.fread(\"/home/rmodi/Documents/CSE519/hw2/dataset/test_identity.csv\").to_pandas()\n",
    "\n",
    "testset = pd.merge(test_transaction, test_identity, on='TransactionID', how='outer')\n",
    "%reset_selective -f test_transaction\n",
    "%reset_selective -f test_identity\n",
    "\n",
    "testset = testset[[\"TransactionID\",\"DeviceType\",\"DeviceInfo\",\"TransactionDT\",\"TransactionAmt\",\"ProductCD\",\"card4\",\"card6\",\"P_emaildomain\",\"R_emaildomain\",\"addr1\",\"addr2\",\"dist1\",\"dist2\"]]\n",
    "\n",
    "testset['TransactionDT_day'] = testset['TransactionDT'].apply(lambda x: int(x/86400))\n",
    "testset['TransactionDT_hour'] = testset['TransactionDT'].apply(lambda x: int(x/86400%1*24))\n",
    "testset['TransactionDT_min'] = testset['TransactionDT'].apply(lambda x: int(x/86400%1*24%1*60))\n",
    "testset['TransactionDT_sec'] = testset['TransactionDT'].apply(lambda x: int(x/86400%1*24%1*60%1*60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of trainset for easy resetting\n",
    "dataset = testset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace columns that have empty value with 'unknown' value\n",
    "cols = ['card4', 'card6', 'DeviceType', 'DeviceInfo', 'P_emaildomain', 'R_emaildomain']\n",
    "dataset[cols] = dataset[cols].replace({'': 'unknown'})\n",
    "\n",
    "# Keep the top 5 column values and group remaining ones into 'Others'\n",
    "top5_deviceinfo = set(dataset['DeviceInfo'].value_counts()[:5].index)\n",
    "dataset['DeviceInfo'] = dataset['DeviceInfo'].apply(lambda x: x if x in top5_deviceinfo else 'Others')\n",
    "\n",
    "# Group categories that are similar into one category [4]\n",
    "regex_patterns = {\n",
    "    r'^frontier.*$': 'frontier.com',\n",
    "    r'^gmail.*$': 'gmail.com',\n",
    "    r'^hotmail.*$': 'hotmail.com',\n",
    "    r'^live.*$': 'live.com',\n",
    "    r'^netzero.*$': 'netzero.com',\n",
    "    r'^outlook.*$': 'outlook.com',\n",
    "    r'^yahoo.*$': 'yahoo.com'\n",
    "}\n",
    "replacements = {\n",
    "    'P_emaildomain': regex_patterns,\n",
    "    'R_emaildomain': regex_patterns\n",
    "}\n",
    "\n",
    "dataset.replace(replacements, regex=True, inplace=True)\n",
    "\n",
    "dataset['hr_sin'] = np.sin((dataset['TransactionDT_hour'] + dataset['TransactionDT_min']/60.0)*(np.pi/12.0))\n",
    "dataset['hr_cos'] = np.cos((dataset['TransactionDT_hour'] + dataset['TransactionDT_min']/60.0)*(np.pi/12.0))\n",
    "dataset['TransactionAmt_lg'] = np.log(dataset['TransactionAmt'])\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "rob_scaler = RobustScaler()\n",
    "dataset['TransactionAmt_scaled'] = rob_scaler.fit_transform(dataset['TransactionAmt'].values.reshape(-1,1))\n",
    "\n",
    "categorical_cols = ['DeviceType', 'ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain']\n",
    "ohe = pd.get_dummies(dataset[categorical_cols])\n",
    "ohe.drop('P_emaildomain_scranton.edu', axis=1, inplace=True)\n",
    "dataset = dataset.join(ohe)\n",
    "\n",
    "train_cols = [\"TransactionAmt_scaled\",\"hr_sin\",\"hr_cos\"] + list(ohe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "clf = joblib.load('models/rs_smote_xgb.pkl')\n",
    "test_preds_proba = clf.predict_proba(dataset[train_cols].values)\n",
    "test_preds = clf.predict(dataset[train_cols].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    376794\n",
       "True     129897\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_preds)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'TransactionID': testset.TransactionID, 'isFraud': test_preds_proba[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('dataset/submission_6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
